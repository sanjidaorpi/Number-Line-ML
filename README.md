# Number Line ML

Number Line ML is a simulation and optimization project that uses a genetic algorithm to evolve strategies for minimizing movement imbalance across multiple agents navigating independent number lines.

## Project Description

The project simulates four agents moving along separate number lines from position 1 to 10. At each step, one agent is selected to move. The objective is to develop a policy for selecting agents in a way that minimizes the total movement imbalance, measured by the sum of squared move counts per agent.

The policy is represented as a state-action table and is optimized over generations using evolutionary strategies including selection, crossover, and mutation.

## Game Rules

- There are four number lines, each starting with an agent at position 1.
- At every time step, one agent is selected to move:
  - If the agent is in position 1, it always moves to position 2.
  - Otherwise, it moves either left or right with equal probability (50%).
- The game ends when any agent reaches position 10.
- The final score is calculated as the **sum of squared move counts** for each agent.
- The goal is to minimize this score, achieving a balanced distribution of moves.

## Optimization Strategy

The project uses a genetic algorithm to optimize decision-making:

- **State Representation**: Each state is defined by the agent's current position and how many times it has moved.
- **Policy Representation**: A table mapping states to action values, which are used to rank agent selections.
- **Fitness Evaluation**: A policyâ€™s fitness is the average final score across multiple game simulations.
- **Selection**: Policies with scores below the median are retained.
- **Crossover**: New policies are generated by combining selected parents.
- **Mutation**: Action values are randomly altered to maintain diversity.

## Key Functions

| Function             | Description |
|----------------------|-------------|
| `create_numberline()` | Initializes a number line with an agent at position 1 |
| `move_point()`        | Moves the selected agent based on the game rules |
| `compute_score()`     | Calculates the final score from move counts |
| `choose_action()`     | Selects the action value for a given state |
| `evaluate_policy()`   | Simulates a full game using the current policy |
| `crossover()`         | Combines two policies to generate a new one |
| `mutate()`            | Randomly alters a policy's actions |

## Simulation Parameters

- Population size: 10
- Number of epochs: 15
- Iterations per evaluation: 80
- Crossover rate: 0.5
- Mutation rate: 0.01

## Results

The simulation tracks the average fitness of the policy population over generations. As the genetic algorithm progresses, the policies evolve to select agents more evenly, resulting in lower and more balanced scores.
